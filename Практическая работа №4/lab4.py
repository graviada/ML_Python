import numpy as np
from matplotlib import pyplot as plt
from scipy.optimize import minimize


# В данной лабораторной работе вам предлагается несколько моделей линейной регрессии и пронаблюдать эффект недообучения,
# переобучения, а так же пронаблюдать соответствующие этим случаям кривые обучения.

# Для выполнения данной лабораторной работы, необходимо заполнить код в следующих фукнциях:
# scale_features - стандартизирует признаки,
# compute_cost - вычисляет функцию стоимости,
# compute_cost_grad - вычисляет градиент фукнции стоимости,
# compute_learning_curves - вычисляет значения кривых обучения.

# Кроме заполнения этих функций настоятельно рекомендуется ознакомится с содержимым остальных функций.
# Комментарии к графикам:
# 1. Исходные данные
# 2. Обученная модель линейной регрессии.
#    Здесь можно наблюдать эффект недообучения модели из-за недостаточной сложности.
# 3. Кривые обучения для недообученной модели, изображенной на графике 2.
#    Можно заметить, что ошибка на всем обучающем наборе и на всем валидационном наборе велика - признак недообучения.
# 4. Обученная модель с полиномиальными признаками. На графике можно наблюдать, как функция проходит почти через
#    все точки обучающего набора (отмечены красными крестами).
# 5. Кривые обучения, соответствующие модели с полиномиальными признаками. Можно наблюдать большой разрыв между ошибкой
#    на всем обучающем наборе и на всем валидационном - признак переобучения.

# ------------------------------------------------КОНСПЕКТ ЛЕКЦИИ------------------------------------------------
# Обучаемые параметры – параметры модели, поиск которых ведется при оптимизации функции стоимости (наши theta).
# Необучаемые параметры (гиперпараметры) – такие параметры, которые нельзя найти с помощью оптимизации
# функции стоимости, но значения которых влияют на результат оптимизации функции стоимости.
# Примеры:
# Скорость обучения
# Количество итераций градиентного спуска
# Количество слоев нейронной сети
# Количество нейронов в скрытых слоях
# Количество синтетических признаков (например, полином)
# Параметр регуляризации
# И другие

# Для подбора гиперпараметров разделим доступные нам данные на три части: обучающую выборку, валидационную
# и тестовую. На обучающей будем подбирать значения обучаемых параметров (theta), на валидационной – гиперпараметров,
# а на тестовой делать вывод о целесообразности использования всей модели в целом.

# В качество критерия подбора значений гиперпараметров используют метрику ошибки алгоритма на валидационном наборе.
# В качестве метрики можно использовать значение самой функции стоимости без регуляризации, долю верно
# классифицированных объектов (для классификации) или что-то более сложное.
# Например, для линейной регрессии часто используется значение самой функции стоимости без регуляризации на
# валидационном наборе. Регуляризация не нужна, поскольку нам интересны отклонения нашей модели (предсказаний) от
# фактических значений. Регуляразиция к тому же добавляет штраф за размер theta. Но нам не важен размер theta, когда мы
# оцениваем ошибку (штраф не является ошибкой).

# Переобучение выражается в малой ошибке на обучающем наборе и большой ошибке на валидационном.
# Недообучение – в большой ошибке на обоих наборах.
# Хорошо, когда ошибка на обоих наборах малая.
# Ошибка на валидационном наборе почти всегда больше, чем на обучающем, даже у хорошей модели. Главное - снизить ошибку
# на валидационном наборе.

# Методы подбора гиперпараметров:
# 1. Случайный поиск (случайным образом подбираем набор гиперпараметров; проверяем, насколько он хорош на валидационной
# выборке или же строим для этого набора кривые обучения; смотрим, насколько они лучше предыдущих и останавливаемся на
# тех, которые дают максимально хорошие кривые обучения - которые быстро вышли на плато, близко к друг другу пролегают
# и недалеко от оси х)
# 2. Поиск по решетке (Grid search) (представим, что есть два гиперпараметра - регуляризации и скорости обучения; мы
# можем задать шаг поиска по одному гиперпараметру и шаг поиска по другому; получаем сетку, в ее узлах соотвествующие
# наборы гиперпараметров; проходим по всей сетке и ищем максимально хорошую комбинацию)
# 3. Генетические алгоритмы (определенный метод оптимизации, модификация случайного поиска с употреблением эвристики)
# 4. Графические методы (строим график ошибки на валидационном наборе при заданном значении гиперпараметра - можно
# 2-х и 3-х мерные графики строить; метод долгий)
# 5. Гибридные алгоритмы (используются комбинации алгоритмов)
# 6. Другие

# Шаги по созданию оптимальной модели:
# 1. Выбрать модель любым способом (обычно начинают с простых).
# 2. Задать значения гиперпараметров случайно или пользуясь эвристикой.
# 3. Разделить набор всех имеющихся данных на три части – обучающий, валидационный и тестовый наборы (примерные
# пропорции: 60%, 20%, 20%). ВАЖНО: перед тем, как разделить наши данные на новые наборы, их нужно перемешать случайным
# образом)
# 4. Построить кривые обучения.
# 5. Если полученные кривые приемлемы, то перейти к шагу 8.
# 6. Попробовать подобрать значения гиперпараметров одним из указанных методов, минимизируя ошибку на валидационном
# наборе или добавить данных, если это возможно и целесообразно.
# 7. Перейти к шагу 4.
# 8. Оценить качество модели на тестовом наборе.
# 9. Если результат неудовлетворительный, то выбрать другую модель и перейти к шагу 2 и по новой к шагу 3.

# В каком случае могут помочь следующие действия?
# 1. Увеличение количества обучающих примеров (при переобучении; нужно больше данных, чтобы модели было сложнее изучить
# все)
# 2. Уменьшение количества признаков (при переобучении)
# 3. Добавление новых признаков (при недообучении)
# 4. Использование полиномиальных признаков (при недообучении; добавляем синтетические признаки)
# 5. Увеличение параметра регуляризации (при переобучении)
# 6. Уменьшение параметра регуляризации (при недообучении)

# Чтобы бороться с несбалансированностью классов вводят понятия полноты и точности.
# ---------------------------------------------------------------------------------------------------------------

def compute_hypothesis(X, theta):
    # Вычисляет вектор значений функции гипотезы на всех наших примерах.
    # Функция для вычисления гипотезы линейной регрессии.
    # Принимает на вход X - матрицу данных, theta - вектор параметров.
    # Возвращает вектор значений функции гипотезы на всех примерах из матрицы X.

    return X @ theta


def train_linear_regression(X_train, y_train, init_theta, lamb):
    # Используем здесь функцию оптимизации из пакета scipy
    # Функция для обучения алгоритма линейной регрессии.
    # Принимает на вход X_train - матрицу данных, y_train - вектор значений целевой переменной,
    # init_theta - вектор начального приближения параметров для старта градиентного спуска,
    # lamb - параметр регуляризации.
    # Возвращает кортеж из двух элементов: флаг успеха минимизации (True или False) и оптимальный вектор параметров.

    opt_theta_obj = minimize(lambda th: compute_cost(X_train, y_train, th, lamb), init_theta,
                             method='BFGS',
                             jac=lambda th: compute_cost_grad(X_train, y_train, th, lamb),
                             options={'gtol': 1e-5, 'maxiter': 300, 'disp': False})

    return opt_theta_obj.success, opt_theta_obj.x


def show_learning_curves(curves):
    # Принимает значения по оси ординат в каждой точке кривых обучения
    # Функция для отрисовки кривых обучения.
    # Принимает на вход список котрежей. Индекс кортежа - координата по оси абсцисс, элементы кортежа - значения
    # кривой обучения на обучающем наборе и валидационном наборе соответственно.

    tr_curve = list(map(lambda x: x[0], curves))
    val_curve = list(map(lambda x: x[1], curves))

    plt.plot(range(1, len(tr_curve) + 1), tr_curve)
    plt.plot(range(1, len(val_curve) + 1), val_curve)

    plt.xlim(2, len(curves) + 1)
    plt.ylim(0, 150)

    plt.title('Кривые обучения')

    plt.ylabel('Ошибка')
    plt.xlabel('Количество примеров в обучающем наборе')

    plt.legend(['Обучающий набор', 'Валидационный набор'])

    plt.show()


def map_features(X, p):
    # Создает фиктивные признаки, чтобы у нас был полином p-ой степени. Здесь признак один. Она просто дополняет
    # Функция для добавления степеней в набор признаков примера.
    # Принимает на вход X - матрицу данных, p - степень результирующего полинома.
    # Возвращает новую матрицу данных, в которую добавлены степени первого (X[:, 1]) признака матрицы данных
    # до p-ой включительно.

    for i in range(2, p + 1):
        X = np.append(X, X[:, 1].reshape(X.shape[0], 1) ** i, axis=1)

    return X


def load_data(data_file_path):
    # Функция для загрузки данных.
    # Принимает на вход путь к файлу.
    # На выход возвращает кортеж из двух элементов:
    # матрицу данных с фиктивным признаком и вектор значений целевой переменной.

    with open(data_file_path) as input_file:
        X = list()
        y = list()
        for line in input_file:
            *row, label = map(float, line.split(','))
            X.append([1] + row)
            y.append(label)
        return np.array(X, float), np.array(y, float)


def scale_features(X):
    # Функция для стандартизации признаков.
    # Принимает на вход матрицу данных X.
    # На выход возвращает кортеж из двух элементов: новую матрицу данных, со стандартизированными признаками и
    # кортеж из двух элементов: вектор средних значений признаков и вектор средних квадратических отклонений.

    result = np.zeros((X.shape[0], X.shape[1] - 1))  # матрица результата, её нужно заполнить.
    mean = np.zeros(X.shape[1] - 1)  # вектор средних значений признаков, его нужно заполнить.

    mean = np.mean(X[:, 1:], axis=0)
    std = np.std(X[:, 1:], axis=0)

    result = (X[:, 1:] - mean) / std

    return np.insert(result, 0, 1, axis=1), (mean, std)


def compute_cost(X, y, theta, lamb):
    # Функция для расчета стоимости (ошибки) модели на наборе данных.
    # Принимает на вход X - матрицу данных, y - вектор значений целевой переменной, theta - вектор параметров,
    # lamb - параметр регуляризации.
    # Возвращает значение функции стоимости на данном наборе данных.

    m, n = X.shape  # количество примеров в выборке и признаков в примере соответственно.
    cost = 0  # значение функции стоимости, его нужно рассчитать.

    cost = 1 / (2 * m) * np.sum((compute_hypothesis(X, theta) - y) ** 2) + (lamb / m) * np.sum(theta ** 2)

    return cost


def compute_cost_grad(X, y, theta, lamb):
    # Функция для расчета градиента функции стоимости в заданной точке.
    # Принимает на вход X - матрицу данных, y - вектор значений целевой переменной,
    # theta - точка, в которой расчитывается градиент, lamb - параметр регуляризации.
    # Возвращает градиент функции стоимости в заданной точке.

    m, n = X.shape  # количество примеров в выборке и признаков в примере соответственно.
    grad = np.zeros(theta.size)  # вектор градиента функции стоимости, его надо рассчитать.

    grad = (1 / m) * ((compute_hypothesis(X, theta) - y).T @ X) + 2 * lamb / m * theta

    return grad


def compute_learning_curves(X_train, y_train, X_val, y_val, lamb):
    # Функция для расчета кривых обучения.
    # Принимает на вход X_train - матрицу данных обучющего набора,
    # y_train - вектор целевой переменной обучающего набора, X_val - матрицу данных валидационного набора,
    # y_val - вектор целевой переменной валидационного набора, lamb - параметр регуляризации.

    # Функция должна вернуть список кортежей. Каждый кортеж состоит из 2-ух элементов. 1-ый элемент кортежа - это
    # ошибка на обучающем наборе, 2-ой элемент - ошибка на валидационном наборе для значения по оси абсцисс, равному i.
    # Значения на оси абцисс - это количество примеров, которые мы берем из обучающего набора для того, чтобы обучить
    # нашу модель (линейную регрессию).

    # На i-ой итерации мы берем i примеров из обучающего набора. На этих i примерах мы обучаем нашу модель. Далее,
    # чтобы посчитать train_error, мы берем нашу модель и вычисляем функцию стоимости на i примерах обучающего набора.
    # Мы будем считать функцию стоимости для train_error, передавая туда не здешнее lamb, а lamb = 0, поскольку нас
    # интересует именно средний квадрат отклонения нашего предсказания от фактического значения без штрафа за сложность
    # модели (без штрафа за большие коэффициенты theta).

    # Для val_error: мы берем нашу обученную модель и прогоняем ее на всех примерах из валидационного набора. Т. е. по
    # сути считаем опять функцию стоимости, но уже на всем валидационном наборе. И lamb = 0.

    m, n = X_train.shape  # количество примеров в выборке и признаков в примере соответственно.
    result = list()  # список значений кривых обучения.
    init_theta = np.ones(X_val.shape[1])

    for i in range(1, m):
        train_error = 0  # значение функции стоимости на i примерах обучающего набора, его необходимо расчитать.
        val_error = 0  # значение функции стоимости на всем валидационном наборе, его необходимо расчитать.

        opt_theta = train_linear_regression(X_train[:i, :], y_train[:i], init_theta, init_lamb)[1]
        print(f'шаг {i}: веса: {opt_theta}')

        train_error = compute_cost(X_train[:i, :], y_train[:i], opt_theta, 0)
        val_error = compute_cost(X_val, y_val, opt_theta, 0)

        result.append((train_error, val_error))

    return result


# Полиномиальная регрессия:
# С увеличением lamb становится больше похоже на экспоненциальный рост.
# При этом если не меняется степень полинома, то плато достигается на 10-20 уровне по ординате.
# С увеличением степени полинома растёт ошибка на валидационном наборе, но на плато всё равно потом выходит.

# Загрузка данных
X_train, y_train = load_data('lab4data1.txt')
X_val, y_val = load_data('lab4data2.txt')
X_test, y_test = load_data('lab4data3.txt')

plt.title('Обучающий набор')
plt.scatter(X_train[:, 1], y_train, c='r', marker='x')
plt.show()

init_theta = np.array([1, 1])
init_lamb = 1.0

print('Значение функции стоимости при theta = [1, 1], lamb = 1.0 (должно быть ~303.993): ',
      compute_cost(X_train, y_train, init_theta, init_lamb))

print('Значение градиента функции стоимости при theta = [1, 1], lamb = 1.0 (должно быть ~[-15.30, 598.25]): ',
      compute_cost_grad(X_train, y_train, init_theta, init_lamb))

print()
print('Обучение модели линейной регрессии..')

success, opt_theta = train_linear_regression(X_train, y_train, init_theta, init_lamb)
print('Минимизация функции стоимости ' + ('прошла успешно.' if success else 'не удалась.'))

plt.title('Обученая модель линейной регрессии при lamb = 1.0')
plt.scatter(X_train[:, 1], y_train, c='r', marker='x')
plt.plot(X_train[:, 1], compute_hypothesis(X_train, opt_theta))
plt.show()

lin_learning_curves = compute_learning_curves(X_train, y_train, X_val, y_val, 0.0)
show_learning_curves(lin_learning_curves)

poly_pow = 8  # степень полинома для полиномиальной регрессии, можно варьировать
poly_lamb = 0.6  # параметр регуляризации для полиномиальной регрессии, можно варьировать

X_train_poly, (mean, std) = scale_features(map_features(X_train, poly_pow))
X_val_poly = scale_features(map_features(X_val, poly_pow))[0]

X_plot_poly = np.array([[i ** p for p in range(poly_pow + 1)] for i in range(-50, 40)], dtype=float)
X_plot_poly[:, 1:] = (X_plot_poly[:, 1:] - mean) / std

print()
print('Обучение модели полномиальной регрессии..')

success, opt_theta = train_linear_regression(X_train_poly, y_train, np.zeros(X_train_poly.shape[1]), poly_lamb)
print('Минимизация функции стоимости ' + ('прошла успешно.' if success else 'не удалась.'))

# Синие крестики - валидационный набор, красные - обучающий.
# Недообучение - значения ошибки находятся далеко от оси х.
# Переобучение - разрыв между кривыми большой при выходе на плато.

plt.title('Обученая модель при lamb = ' + str(poly_lamb))
plt.scatter(X_train_poly[:, 1], y_train, c='r', marker='x')
plt.scatter(X_val_poly[:, 1], y_val, c='b', marker='x')
plt.plot(X_plot_poly[:, 1], compute_hypothesis(X_plot_poly, opt_theta))
plt.show()

poly_learning_curves = compute_learning_curves(X_train_poly, y_train, X_val_poly, y_val, poly_lamb)
show_learning_curves(poly_learning_curves)

X_test = map_features(X_test, poly_pow)
X_test[:, 1:] = (X_test[:, 1:] - mean) / std

print()
print('Оценка качества модели на тестовом наборе:', compute_cost(X_test, y_test, opt_theta, 0.0))
