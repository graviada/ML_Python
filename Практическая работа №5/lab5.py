from PIL import Image
from matplotlib import pyplot as plt
from itertools import product
import random

# ------------------------------------------------ОБУЧЕНИЕ БЕЗ УЧИТЕЛЯ--------------------------------------------------
# Если меток классов или значений целевой вещественной переменной нет, есть только признаки, то мы решаем задачу
# обучения без учителя. Как правило, в таких случаях требуется найти структуру в данных, уменьшить размерность,
# восстановить недостающие данные и так далее.
# ----------------------------------------------------------------------------------------------------------------------

# Задача кластеразиции:
# Выявить структуру в имеющихся данных - выполнить кластеризацию, то есть выявление кластеров по некоторому критерию.
# Кластер – некоторое подмножество объектов выборки.

# Недостатки алгоритма k-средних:
# 1. Необходимость выбора числа кластеров.
# 2. Необходимость выбора метрики сходства.

# -------------------------------------------------АЛГОРИТМ К-СРЕДНИХ---------------------------------------------------
# 1. Выбираем нескольких точек в пространстве признаков (в качестве координат указываются значения признаков),
# называемых центроидами (мю (i), i=1;k, k - количество кластеров) кластеров.
# 2. Для каждого объекта из выборки, находим ближайший к нему центроид. После этого шага, каждому центроиду будет
# соответствовать множество объектов, ближайших к этому центроиду (кластер).
# 3. Для каждого кластера находим его центр. Делается это по следующей формуле: мы берем среднее арифм. по каждой
# координате. Вектор, составленный из средних арифм. координат всех объектов кластера - это центр этого кластера.
# 4. Все центроиды переносятся в центры соответствующих кластеров.
# 5. Если оказалось, что центры кластеров совпали с положением центроидов, то завершаем алгоритм. В противном случае
# мы переходим к шагу 2 и так до тех пор, пока условие на 5 шаге не начнет выполняться.
# ----------------------------------------------------------------------------------------------------------------------

# Алгоритм k-средних является жадным: на каждом шаге принимает такое действие, которое оптимально именно для этого шага,
# а не для всего алгоритма. Не факт, что мы придем к оптимальному глобальному решению. Из-за этого возникает несколько
# решений задач. Одни и те же объекты можно по-разному разбить на кластеры, в зависимости от выбора начального положения
# центроида.

# Задачу на одном шаге алгоритма k-средних можно представить, как задачу оптимизации. Вводится некоторая функция,
# которая зависит от положения всех центроидов. Мы пытаемся минимизировать эту целевую функцию по координатам всех
# центроидов. Двумя палочками в формуле обозначается подобие расстояния, некая метрика сходства.
# Центр кластера - это оптимальное положение центроида.

# Постановка задачи через оптимизацию позволяет нам сравнивать различные разбиения. Наименьшее значение целевой функции
# соответствует лучшему решению.

# Для выбора положения центроидов часто случайно выбирают K объектов выборки и ставят на их места центроиды. К объектов
# выбирают без повторений. На место K различных объектов ставим центроиды. Все объекты находятся в признаковом
# пространстве, там же находятся центроиды. Нам нужно понимать, как локализованы объекты в этом пространстве признаков.
# В положения объектов мы ставим центроиды. Это гарантирует нам, что центроиды окажутся там же, где и объекты.
# Таким образом, если в данных нет повторов, мы гарантируем наличие центроидов в одной точке.
# Случайность позволяет запустить алгоритм несколько раз и выбрать лучший (применить случайный поиск).

# Выбор количества кластеров часто обусловлен содержанием задачи.
# Например, если мы знаем, что собирались данные о двух группах разных людей, то разумно будет попробовать разделить
# данные на два кластера.
# Если априорные предположения сделать сложно, то пользуются “методом сломанной трости” (локтя): строят график кривой.
# Берут целевую функцию, выбирают несколько кластеров и ставят им значения полученной целевой функции и отмечают его на
# графике. Чем больше кластеров, тем меньше значение расстояния до них. Точка, где происходит перелом, выбирается за
# количество кластеров.

# Кроме количества кластеров требует выбора также метрика сходства между объектами. Нужно определить, каким образом мы
# будем считать один объект похожим на другой. При этом мы говорим, что будем искать ближайший к объектам центроид.
# Нужно понять, что имеется в виду под "ближайший объект".
# Этот выбор также часто диктуется условием задачи, но часто используют евклидову метрику.
# Также важна нормировка признаков, чтобы признаки с большим масштабом не вносили больший вес.
# В некоторых случаях после нормировки признаков, некоторые из них можно умножить на положительную константу, чтобы
# увеличить вес, если это необходимо.

# В данной части лабораторной работе предлагается кластеризовать данные с помощью алгоритма k-средних.
# В качестве данных предлагается картинка в формате RGB. Необходимо кластеризовать пиксели по цветам, усреднить цвет в
# полученных кластерах и снизить в итоге количество цветов, используемых для отображения картинки.

# Сколько хотим цветов - столько и будет кластеров.

# Для выполнения данной работы необходимо заполнить код в следующих функциях:
# 1. init_centroids - расчет начальных положений центроидов
# 2. find_closest_centroid - нахождение ближайшего центроида к какой-то конкретной точке
# 3. compute_cluster_center - расчет центра кластера
# 4. kmeans - реализация алгоритма k-средних


def init_centroids(data, k):

    # Функция для расчета начальных положений центроидов. Случайным образом расположить центроиды в пространстве
    # признаков.
    # Принимает data - список кортежей - точек в пространстве признаков (каждый кортеж содержит в себе 3 элемента,
    # соотвествующих RGB-координатам цвета какого-то конркетного пикселя),
    # k - желаемое число кластеров (и центроидов, соответственно).
    # Должна вернуть список начальных положений центроидов. Предлагается выбрать случайно k объектов из data и
    # поставить в их положения центроиды. Предлагается использовать random.shuffle(). Выбрать k объектов без повторений.

    result = list()  # список положений (кортежей) центроидов, нужно заполнить.
    random.shuffle(data)

    for i in range(1, k + 1):
        result.append(data[i])

    return result


def find_closest_centroid(value, centroids):

    # Функция для нахождения ближайшего центроида к заданной точке в пространстве признаков.
    # Принимает value - точка (кортеж из 3 элементов - RGB-компоненты) в пространстве признаков, centroids - список
    # кортежей положений центроидов.
    # Должна вернуть индекс ближайшего центроида в списке centroids. Ближайший ищем, используем евклидову метрику (сумма
    # квадратов под корнем).

    euclidean_metric = []

    for i in range(len(centroids)):
        distance = 0
        for j in range(len(value)):
            distance += (centroids[i][j] - value[j]) ** 2
        euclidean_metric.append(distance ** 0.5)

    closest_index = euclidean_metric.index(min(euclidean_metric))  # индекс ближайшего центроида из списка центроидов

    return closest_index


def compute_cluster_center(cluster_data):

    # Функция для расчета центра кластера. Находим среднее по всем координатам точек в кластере (по 1/2/3-ой координате
    # среднее арифметическое - это и будут координаты центра).
    # Принимает на вход cluster_data - список кортежей точек в
    # пространстве признаков, соответствующих данным из выборки.
    # Должна вернуть кортеж - центр кластера.

    result = [] # центр кластера в виде списка, его нужно заполнить

    for i in range(len(cluster_data[0])):
        sum_of_coordinate = 0
        for j in range(len(cluster_data)):
            sum_of_coordinate += cluster_data[j][i]
        result.append(sum_of_coordinate / len(cluster_data))

    return tuple(round(r) for r in result)


def kmeans(data, k):

    # Функция, реализующая алгоритм k-средних.
    # Принимает на вход data - список положений (кортежей) точек в пространстве признаков (по сути, данные),
    # k - число желаемых кластеров в итоге.
    # Должна вернуть список кластеров (списков) положений (кортежей), содержащих все точки, принадлежащие всем
    # кластерам, и список положений (кортежей) центроидов соответствующих кластеров.

    centroids = init_centroids(data, k)  # список положений центроидов, его нужно посчитать
    while True:

        clusters = [list() for _ in centroids]  # список списков положений точек для всех центроидов (пока пустой)
        for value in data:
            cent_index = find_closest_centroid(value, centroids)
            clusters[cent_index].append(value)

        # Мы заполнили кластеры нужными значениями.
        # Необходимо написать код, который будет вычислять центры кластеров (фукнцию вы уже реализовали),
        # затем переносить соответствующие центроиды в эти центры. Выход из цикла должен происходить тогда, когда новый
        # расчет центра совпал с текущим положением центроида для всех центроидов.

        flag = 0

        for i in range(len(clusters)):
            center = compute_cluster_center(clusters[i])
            if centroids[i] == center:
                flag += 1
            else:
                centroids[i] = center

        if flag == len(clusters):
            break

    return clusters, centroids


model_centers = [(0, 0), (70, 10), (30, 40)]
model_data = [(random.gauss(c[0], 7), random.gauss(c[1], 7)) for c in model_centers for _ in range(100)]

plt.scatter(*[list(map(lambda x: x[i], model_data)) for i in range(2)], marker='o')
plt.show()

model_clusts, model_centrs = kmeans(model_data, 3)
print(f'Положения центроидов для модельного случая (должны быть близки к {model_centers} с точностью до порядка): '
      f'{model_centrs}')

for i in range(len(model_clusts)):
    plt.scatter(*[list(map(lambda x: x[j], model_clusts[i])) for j in range(2)],
                marker='o',
                c=('r', 'g', 'b')[i])
plt.scatter(*[list(map(lambda x: x[j], model_centrs)) for j in range(2)],
            marker='x',
            c='black', s=[100] * len(model_clusts))
plt.show()

print()
print('Загруза картинки из файла "image.png".')
image = Image.open('image.png')
image_pixels = image.load()
data = [image_pixels[x, y] for x, y in product(range(image.size[0]), range(image.size[1]))]

# количество цветов, которе остается на результирующей картинке (можно поварьировать,
# но от него сильно зависит время выполнения)
clusters_num = 32

print()
print('Запуск алгоритма k-средних (может занять время..)')
clusts, centrs = kmeans(data, clusters_num)


print('Сокращение количества цветов на картинке.')
for x, y in product(range(image.size[0]), range(image.size[1])):
    for i in range(len(clusts)):
        if image_pixels[x, y] in clusts[i]:
            image_pixels[x, y] = centrs[i]
            break
image.save('result.png')

print('Успех! Результат в файле "result.png" (обратите внимаение на размер результата в килобайтах).')